<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AnoTe – Presentation</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
    <style>
    :root {
      --primary: #7c4dff;
      --secondary: #ede7f6;
      --bg: #fefcff;
      --dark: #2e1f3b;
      --text: #3b2d4a;
      --light: #fff;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', sans-serif;
      background: var(--bg);
      color: var(--text);
      scroll-behavior: smooth;
    }

    header.hero {
      background: linear-gradient(120deg, var(--primary), #b39ddb);
      color: white;
      padding: 120px 30px;
      text-align: center;
    }

    .hero h1 {
      font-size: 5.5em;
      font-weight: 800;
    }

    .hero p {
      margin-top: 20px;
      font-size: 1.9em;
      opacity: 0.95;
    }

    nav {
      position: sticky;
      top: 0;
      background: var(--light);
      padding: 10px 20px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
      display: flex;
      justify-content: center;
      gap: 30px;
      z-index: 1000;
    }

    nav a {
      color: var(--primary);
      font-weight: 600;
      text-decoration: none;
      padding: 8px 12px;
      border-radius: 8px;
    }

    nav a:hover {
      background: var(--secondary);
    }

    section {
      max-width: 1200px;
      margin: 80px auto;
      padding: 0 20px;
    }

    section h2 {
      font-size: 2em;
      margin-bottom: 20px;
      color: var(--primary);
    }

    .card {
      background: white;
      border-radius: 16px;
      padding: 30px;
      margin-bottom: 30px;
      box-shadow: 0 4px 16px rgba(124, 77, 255, 0.1);
 
    text-align: justify;
  
    }

    .card img {
      width: 100%;
      border-radius: 12px;
      margin-top: 20px;
      box-shadow: 0 4px 12px rgba(123, 44, 191, 0.12);
    }

    footer {
      text-align: center;
      padding: 60px 20px;
      background: var(--secondary);
      font-size: 0.9em;
      color: #6c5b7b;
    }

    @keyframes backgroundShift {
  0% {
    background-position: 0% 50%;
  }
  50% {
    background-position: 100% 50%;
  }
  100% {
    background-position: 0% 50%;
  }

}

header.hero {
  background: linear-gradient(120deg, var(--primary), #b39ddb, #9575cd);
  background-size: 300% 300%;
  animation: backgroundShift 10s ease infinite;
  color: white;
  padding: 120px 30px;
  text-align: center;
}

  </style>
</head>
<body>
  <header class="hero">
    <h1>AnoTe</h1>
    <p>An adaptive text annotation system using large language models</p>
  </header>
  <div style="text-align:right; padding: 10px 20px;">
    <a href="index.html">PL</a> | <a href="index-en.html">EN</a>
  </div>
  <nav>
    <a href="#intro">Introduction</a>
    <a href="#research">Research</a>
    <a href="#explain">Explainability</a>
    <a href="#app">Application</a>
    <a href="#summary">Summary</a>
    <a href="#contact">Contact</a>
  </nav>

  <section id="intro">
    <h2>Introduction</h2>
    <div class="card">
      <p>Manual text annotation is costly, time-consuming, and error-prone. It requires expert knowledge, which makes the process difficult to scale. AnoTe addresses this problem through an adaptive annotation automation system using large language models.</p>
    </div>
  </section>

  <section id="research">
    <h2>Selection Strategies</h2>
    <div class="card">
      <p>The selection of examples for prompting has a significant impact on the effectiveness of large language models in annotation tasks. The data chosen as exemplars can substantially affect the quality of predictions, either improving or degrading it. The project implemented and tested both classic and novel methods. Among the classical ones, strategies based on randomness, model uncertainty, and chain-of-thought reasoning were considered. Other approaches included selecting unstable classifications, representative data in semantic graphs, and mixtures of Gaussian distributions. Experiments were conducted on six datasets and three large language models. The best results were obtained using chain-of-thought prompting with five stochastic generations at temperature 0.3, choosing the most frequent variant as the final prediction. In most datasets, this led to improvements over random selection. However, no universal strategy was found for all cases. Methodological frameworks are needed for strategy selection depending on task, data, and model. One challenge is that large language models are sensitive to subtle changes in prompting that may not affect humans, yet can lead to significantly different outputs.</p>
      <img src="selection.png" alt="Selection Strategies">
    </div>
  </section>

  <section id="explain">
    <h2>Explainability</h2>
    <div class="card">
      <p>Techniques such as SHAP, occlusion, and self-explaining mechanisms were applied. These allow for insights into the model's reasoning, increasing user trust and helping identify potential errors or biases.</p>
    </div>
  </section>

  <section id="app">
    <h2>Application</h2>
    <div class="card">
      <p>The research results were integrated into an application that enables annotation of any text dataset with chosen labels. The app suggests examples for manual annotation, allows explanation generation for any instance, and evaluates model predictions. Corrected examples are automatically added to the prompt set.</p>
      <img src="app.png" alt="Application">
    </div>
  </section>

  <section id="summary">
    <h2>Summary</h2>
    <div class="card">
      <p>Using chain-of-thought reasoning proves to be not only an effective tool supporting the annotation process but also a key element in improving the explainability of large language models. This enables better understanding of model decisions and builds trust in the results. Despite the impressive potential of LLMs – in both contextual understanding and adaptation to complex language tasks – their limitations must not be ignored. These models can still produce errors, require expert oversight, and behave unpredictably in certain scenarios. Therefore, their use in annotation must be conscious, flexible, and critical – combining technological capability with research responsibility and practical caution. Only then can the potential of LLMs be safely and effectively utilized in language processing.</p>
    </div>
  </section>

  <section id="contact">
    <h2>Contact</h2>
    <div class="card">
      <p>Magdalena Sęga</p>
      <p>Izabela Szkaradek</p>
      <p>Julita Wójcik <a href="mailto:julitawjck@gmail.com">julitawjck@gmail.com</a></p>
      <p>Nilam Zygmunt</p>
    </div>
  </section>

  <footer>
    &copy; 2025 AnoTe
  </footer>
</body>
</html>