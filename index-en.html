<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AnoTe</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <style>
    :root {
      --primary: #7c4dff;
      --secondary: #ede7f6;
      --bg: #fefcff;
      --dark: #2e1f3b;
      --text: #3b2d4a;
      --light: #fff;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', sans-serif;
      background: var(--bg);
      color: var(--text);
      scroll-behavior: smooth;
    }

    header.hero {
      background: linear-gradient(120deg, var(--primary), #b39ddb, #9575cd);
      background-size: 300% 300%;
      animation: backgroundShift 10s ease infinite;
      color: white;
      padding: 120px 30px;
      text-align: center;
    }

    @keyframes backgroundShift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    .hero h1 {
      font-size: 5.5em;
      font-weight: 800;
    }

    .hero p {
      margin-top: 20px;
      font-size: 1.9em;
      opacity: 0.95;
    }

    .menu-toggle {
      display: none;
      background: none;
      border: none;
      font-size: 1.5em;
      padding: 10px;
      cursor: pointer;
    }

    nav {
      position: sticky;
      top: 0;
      background: var(--light);
      padding: 10px 20px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 20px;
      z-index: 1000;
    }

    nav a {
      color: var(--primary);
      font-weight: 600;
      text-decoration: none;
      padding: 8px 12px;
      border-radius: 8px;
    }

    nav a:hover {
      background: var(--secondary);
    }

    section {
      max-width: 1200px;
      margin: 80px auto;
      padding: 0 20px;
    }

    section h2 {
      font-size: 2em;
      margin-bottom: 20px;
      color: var(--primary);
    }

    .card {
      background: white;
      border-radius: 16px;
      padding: 30px;
      margin-bottom: 30px;
      box-shadow: 0 4px 16px rgba(124, 77, 255, 0.1);
      text-align: justify;
    }

    .card img {
      width: 100%;
      border-radius: 12px;
      margin-top: 20px;
      box-shadow: 0 4px 12px rgba(123, 44, 191, 0.12);
    }

    footer {
      text-align: center;
      padding: 60px 20px;
      background: var(--secondary);
      font-size: 0.9em;
      color: #6c5b7b;
    }

    @media (max-width: 768px) {
      .hero h1 { font-size: 3em; }
      .hero p { font-size: 1.2em; }
      .menu-toggle { display: block; margin: 0 auto 10px; }
      nav { display: none; flex-direction: column; align-items: center; }
      nav.show { display: flex; }
      section { padding: 0 10px; margin: 40px auto; }
      .card { padding: 20px; }
      footer { padding: 30px 10px; }
    }
  </style>
</head>
<body>
  <header class="hero">
    <h1>AnoTe</h1>
    <p>Adaptive text annotation system using large language models</p>
  </header>

  <div style="text-align:right; padding: 10px 20px;">
    <a href="index.html">PL</a> | <a href="index-en.html">EN</a>
  </div>

  <button class="menu-toggle" onclick="document.querySelector('nav').classList.toggle('show')">
    &#9776; Menu
  </button>

  <nav>
    <a href="#intro">Motivation</a>
    <a href="#research">Selection Strategies</a>
    <a href="#explain">Explainability</a>
    <a href="#app">Application</a>
    <a href="#summary">Summary</a>
    <a href="#contact">Contact</a>
  </nav>

  <section id="intro">
    <h2>Motivation</h2>
    <div class="card">
      <p>Manual text annotation is costly, time-consuming, and error-prone. It requires expert knowledge, making the process difficult to scale. AnoTe addresses this issue with an adaptive annotation automation system using large language models.</p>
    </div>
  </section>

  <section id="research">
    <h2>Selection Strategies</h2>
    <div class="card">
      <p>The selection of examples for prompting significantly affects the performance of large language models in annotation tasks. The quality of predictions can improve or degrade depending on which data is presented as examples. The project implemented and tested both classical and novel methods. Classical methods included random selection, uncertainty-based strategies, and chain-of-thought techniques. We also explored choosing unstable classifications, semantically representative data, and mixtures of Gaussian distributions. Experiments were conducted on six datasets using three LLMs. The best results were achieved with chain-of-thought reasoning using five stochastic generations at temperature 0.3, selecting the most frequent variant as the final prediction. Most datasets showed improvement over random baselines. However, no universal strategy worked for all cases. A methodological framework is needed to select strategies depending on the task, data, and model. A key challenge is that large language models are sensitive to small changes in prompts that may be insignificant to humans but lead to major shifts in model output.</p>
      <img src="selection.png" alt="Selection Strategies">
    </div>
  </section>

  <section id="explain">
    <h2>Explainability</h2>
    <div class="card">
      <p>Explanations help users understand why large language models make certain decisions.
As part of the project, three types of explanation generation methods were implemented and compared: occlusion, SHAP, and self-explanations. It was found that the generated explanations vary significantly depending on the method and the model used. While some consistency can be observed with short texts, longer texts reveal a clear divergence in the identified key elements.

For this reason, our approach involves combining the results from all three methods to create a comprehensive and final explanation for each record. The research showed that there is no single universal method for generating explanations for language models. Their characteristics and consistency are highly dependent on the properties of the datasets. Additionally, explanation faithfulness remains a key challenge.

</p>
      <img src="exp.png" alt="Explainability">
    </div>
  </section>

  <section id="app">
    <h2>Application</h2>
    <div class="card">
      <p>The research results were integrated into an application that enables annotation of any text dataset using selected labels. The app suggests examples for manual annotation, provides explanations for any instance, and evaluates model predictions. Corrected examples are automatically added to the prompt set.</p>
      <img src="app.png" alt="Application">
    </div>
  </section>

  <section id="summary">
    <h2>Summary</h2>
    <div class="card">
      <p>Chain-of-thought reasoning proves to be not only an effective annotation aid but also a key factor in enhancing the explainability of large language models. This allows better understanding of model decisions and builds trust in the generated outcomes. Despite their impressive potential in understanding context and adapting to complex tasks, LLMs have limitations. They can still produce errors, require expert oversight, and behave unpredictably in some scenarios. Thus, their use in annotation tasks requires a conscious, flexible, and critical approach—one that combines technological capabilities with research responsibility and practical caution. Only then can LLMs be safely and effectively used in language processing and understanding tasks.</p>
    </div>
  </section>

  <section id="contact">
    <h2>Contact</h2>
    <div class="card">
      <p>Magdalena Sęga</p>
      <p>Izabela Szkaradek</p>
      <p>Julita Wójcik <a href="mailto:julitawjck@gmail.com">julitawjck@gmail.com</a></p>
      <p>Nilam Zygmunt</p>
    </div>
  </section>

  <footer>
    &copy; 2025 AnoTe
  </footer>
</body>
</html>
<script>
  // Optional: auto-close nav on link click (mobile UX improvement)
  document.querySelectorAll('nav a').forEach(link => {
    link.addEventListener('click', () => {
      document.querySelector('nav').classList.remove('show');
    });
  });
</script>
